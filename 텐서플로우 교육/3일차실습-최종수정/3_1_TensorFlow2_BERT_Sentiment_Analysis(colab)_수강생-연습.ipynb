{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o2nRY4GyKWqL"
   },
   "source": [
    "# TensorFlow 2 - BERT: Movie Review Sentiment Analysis\n",
    "\n",
    "$BERT$는 트랜스포머의 한 부분인 양방향 인코더이다.사전학습된 BERT 모델을 미세조정하면 광범위한 Q&A, 감성분석과 개체명 인식 등의 자연어 처리 작업을 위한 최신 모델을 만들 수 있다. $BERT_{BASE}$ 는 총 110M (L=12, H=768, A=12, Total Parameters=110M)개의 파라미터를 가지고, $BERT_{LARGE}$는 총 340M (L=24, H=1024, A=16, Total Parameters=340M)를 가진다. (Devlin et al, 2019, [BERT paper link](https://arxiv.org/pdf/1810.04805.pdf)).\n",
    "\n",
    "\n",
    "**Dataset**\n",
    "\n",
    "IMDB 데이터셋은 자연어 처리를 위한 5만개의 영화평으로 구성된다. 캐글 링크(https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews)에서 다운로드할 수 있다.\n",
    "\n",
    "\n",
    "**과제**\n",
    "\n",
    "IMDB 데이터셋의 평은 긍정 또는 부정이다. 따라서 자연어 처리(NLP) 영화평 감성분석 작업은 지도학습 이진 분류문제이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bvh3ECwPcRI6",
    "outputId": "7a21c56f-6b6f-409c-b70d-1d0180d2910f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bert-for-tf2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/d3/820ccaf55f1e24b5dd43583ac0da6d86c2d27bbdfffadbba69bafe73ca93/bert-for-tf2-0.14.7.tar.gz (41kB)\n",
      "\r",
      "\u001b[K     |████████                        | 10kB 23.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████                | 20kB 10.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▉        | 30kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▉| 40kB 7.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 51kB 4.6MB/s \n",
      "\u001b[?25hCollecting py-params>=0.9.6\n",
      "  Downloading https://files.pythonhosted.org/packages/a4/bf/c1c70d5315a8677310ea10a41cfc41c5970d9b37c31f9c90d4ab98021fd1/py-params-0.9.7.tar.gz\n",
      "Collecting params-flow>=0.8.0\n",
      "  Downloading https://files.pythonhosted.org/packages/a9/95/ff49f5ebd501f142a6f0aaf42bcfd1c192dc54909d1d9eb84ab031d46056/params-flow-0.8.2.tar.gz\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.18.5)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.41.1)\n",
      "Building wheels for collected packages: bert-for-tf2, py-params, params-flow\n",
      "  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.7-cp36-none-any.whl size=30537 sha256=e871140362addbe8ee57c6bc1d779bd2e5300fadd3fff615f69ec7a10f8749ea\n",
      "  Stored in directory: /root/.cache/pip/wheels/e1/f8/e2/b98f79a6b8cc898d8e4102b83acb8a098df7d27500a2bac912\n",
      "  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for py-params: filename=py_params-0.9.7-cp36-none-any.whl size=7302 sha256=584dd637e463035cc0b8060d9466707395b3dc399aff87bdb8186bed77f672cc\n",
      "  Stored in directory: /root/.cache/pip/wheels/67/f5/19/b461849a50aefdf4bab47c4756596e82ee2118b8278e5a1980\n",
      "  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for params-flow: filename=params_flow-0.8.2-cp36-none-any.whl size=19475 sha256=1ba95f17448497f61ca6025755e5ab0cfa8ea27aaa4e8f43a419a0dc4528d121\n",
      "  Stored in directory: /root/.cache/pip/wheels/08/c8/7f/81c86b9ff2b86e2c477e3914175be03e679e596067dc630c06\n",
      "Successfully built bert-for-tf2 py-params params-flow\n",
      "Installing collected packages: py-params, params-flow, bert-for-tf2\n",
      "Successfully installed bert-for-tf2-0.14.7 params-flow-0.8.2 py-params-0.9.7\n"
     ]
    }
   ],
   "source": [
    "# 버트를 설치한다.\n",
    "!pip install bert-for-tf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dotZjUvecRI8",
    "outputId": "d4a7ac9a-3fe0-4fe2-8a51-e757460c856c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.3.0\n",
      "Hub version:  0.10.0\n"
     ]
    }
   ],
   "source": [
    "# 필요한 모듈들을 임포트한다.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bert\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import  Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"TensorFlow Version:\",tf.__version__)\n",
    "print(\"Hub version: \",hub.__version__)\n",
    "pd.set_option('display.max_colwidth',1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-uH1zw2Pa13m"
   },
   "source": [
    "## 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5IYBmHf_siQO",
    "outputId": "f0bac03b-3484-4a14-d124-515fef29fafd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "3emF0fZwhyPZ"
   },
   "outputs": [],
   "source": [
    "# df=pd.read_csv('/content/drive/My Drive/IMDB Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "W379xRxlMbtb"
   },
   "outputs": [],
   "source": [
    "# IMDB 데이터셋을 판다스 프레임워크로 읽어 들인다.\n",
    "df=pd.read_csv('IMDB Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 699
    },
    "id": "5GbNMjbS_b8J",
    "outputId": "e78a1b06-caf9-47e9-861c-aa929268e48d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.&lt;br /&gt;&lt;br /&gt;The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.&lt;br /&gt;&lt;br /&gt;It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.&lt;br /&gt;&lt;br /&gt;I would say the main appeal of the show is due to the...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. &lt;br /&gt;&lt;br /&gt;The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master's of comedy and his life. &lt;br /&gt;&lt;br /&gt;The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional 'dream' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell's murals decorating every surface) are terribly well done.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well bread suspected serial killer). While some may be disappointed when they realize this is not Match Point 2: Risk Addiction, I thought it was proof that Woody Allen is still fully in control of the style many of us have grown to love.&lt;br /&gt;&lt;br /&gt;This was the most I'd laughed at one of Woody's comedies in years (dare I say a decade?). While I've never been impressed with Scarlet Johanson, in this she managed to tone down her \"sexy\" image and jumped right into a average, but spirited young woman.&lt;br /&gt;&lt;br /&gt;This may not be the crown jewel of his career, but it was wittier than \"Devil Wears Prada\" and more interesting than \"Superman\" a great comedy to go see with friends.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet &amp; his parents are fighting all the time.&lt;br /&gt;&lt;br /&gt;This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.&lt;br /&gt;&lt;br /&gt;OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing &amp; arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.&lt;br /&gt;&lt;br /&gt;3 out of 10 just for the well playing parents &amp; descent dialogs. As for the shots with Jake: just ignore them.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is a visually stunning film to watch. Mr. Mattei offers us a vivid portrait about human relations. This is a movie that seems to be telling us what money, power and success do to people in the different situations we encounter. &lt;br /&gt;&lt;br /&gt;This being a variation on the Arthur Schnitzler's play about the same theme, the director transfers the action to the present time New York where all these different characters meet and connect. Each one is connected in one way, or another to the next person, but no one seems to know the previous point of contact. Stylishly, the film has a sophisticated luxurious look. We are taken to see how these people live and the world they live in their own habitat.&lt;br /&gt;&lt;br /&gt;The only thing one gets out of all these souls in the picture is the different stages of loneliness each one inhabits. A big city is not exactly the best place in which human relations find sincere fulfillment, as one discerns is the case wi...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    review sentiment\n",
       "0  One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the...  positive\n",
       "1   A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master's of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional 'dream' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell's murals decorating every surface) are terribly well done.  positive\n",
       "2                                                                           I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well bread suspected serial killer). While some may be disappointed when they realize this is not Match Point 2: Risk Addiction, I thought it was proof that Woody Allen is still fully in control of the style many of us have grown to love.<br /><br />This was the most I'd laughed at one of Woody's comedies in years (dare I say a decade?). While I've never been impressed with Scarlet Johanson, in this she managed to tone down her \"sexy\" image and jumped right into a average, but spirited young woman.<br /><br />This may not be the crown jewel of his career, but it was wittier than \"Devil Wears Prada\" and more interesting than \"Superman\" a great comedy to go see with friends.  positive\n",
       "3                                                                                                                                                                                                                                                             Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br /><br />OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them.  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is a visually stunning film to watch. Mr. Mattei offers us a vivid portrait about human relations. This is a movie that seems to be telling us what money, power and success do to people in the different situations we encounter. <br /><br />This being a variation on the Arthur Schnitzler's play about the same theme, the director transfers the action to the present time New York where all these different characters meet and connect. Each one is connected in one way, or another to the next person, but no one seems to know the previous point of contact. Stylishly, the film has a sophisticated luxurious look. We are taken to see how these people live and the world they live in their own habitat.<br /><br />The only thing one gets out of all these souls in the picture is the different stages of loneliness each one inhabits. A big city is not exactly the best place in which human relations find sincere fulfillment, as one discerns is the case wi...  positive"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋을 본다\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gbcp65zz_7wk",
    "outputId": "cada5fc3-857d-4d23-ea7e-5fb5fad0e941"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows and columns in the dataset is: (50000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of rows and columns in the dataset is: {}\".format(df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h_uP_hOAR_ac",
    "outputId": "19d20781-7558-46ea-dab2-b2bff9ac8898"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측치를 검사한다.\n",
    "df.apply(lambda x: sum(x.isnull()), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AelQrBAeAEuJ",
    "outputId": "4f380f6b-4daa-4693-962b-25ae8f4a0b0e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    25000\n",
       "positive    25000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 타겟 클래스 밸런스를 검사한다.\n",
    "df[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ESyS2xsQbQlm"
   },
   "outputs": [],
   "source": [
    "# BERT 임베딩을 위한 함수들: input_ids, input_masks, input_segments와 Inputs\n",
    "MAX_SEQ_LEN=500 # 최대 시퀀스 길이(max sequence length)\n",
    "\n",
    "def get_masks(tokens):\n",
    "    \"\"\"매스크: 토큰에 대해 1 패딩에 대해 0 할당\"\"\"\n",
    "    return [1]*len(tokens) + [0] * (MAX_SEQ_LEN - len(tokens))\n",
    " \n",
    "def get_segments(tokens):\n",
    "    \"\"\"세그먼트: 처음 문장은 0 그리고 두번째문장은 1\"\"\"  \n",
    "    segments = []\n",
    "    current_segment_id = 0\n",
    "    for token in tokens:\n",
    "        segments.append(current_segment_id)\n",
    "        if token == \"[SEP]\":\n",
    "            current_segment_id = 1\n",
    "    return segments + [0] * (MAX_SEQ_LEN - len(tokens))\n",
    "\n",
    "def get_ids(tokens, tokenizer):\n",
    "    \"\"\"토크나이저 단어집의 토큰 아이디\"\"\"\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(tokens,)\n",
    "    input_ids = token_ids + [0] * (MAX_SEQ_LEN - len(token_ids))\n",
    "    return input_ids\n",
    "\n",
    "def create_single_input(sentence, tokenizer, max_len):\n",
    "    \"\"\"문장으로부터 입력을 만든다.\"\"\"\n",
    "    stokens = tokenizer.tokenize(sentence)\n",
    "    stokens = stokens[:max_len]\n",
    "    stokens = [\"[CLS]\"] + stokens + [\"[SEP]\"]\n",
    " \n",
    "    ids = get_ids(stokens, tokenizer)\n",
    "    masks = get_masks(stokens)\n",
    "    segments = get_segments(stokens)\n",
    "\n",
    "    return ids, masks, segments\n",
    " \n",
    "def convert_sentences_to_features(sentences, tokenizer):\n",
    "    \"\"\"문장을 특성으로 변환한다.: input_ids, input_masks와 input_segments\"\"\"\n",
    "    input_ids, input_masks, input_segments = [], [], []\n",
    " \n",
    "    for sentence in tqdm(sentences,position=0, leave=True):\n",
    "      ids,masks,segments=create_single_input(sentence,tokenizer,MAX_SEQ_LEN-2)\n",
    "      assert len(ids) == MAX_SEQ_LEN\n",
    "      assert len(masks) == MAX_SEQ_LEN\n",
    "      assert len(segments) == MAX_SEQ_LEN\n",
    "      input_ids.append(ids)\n",
    "      input_masks.append(masks)\n",
    "      input_segments.append(segments)\n",
    "\n",
    "    return [np.asarray(input_ids, dtype=np.int32), \n",
    "          np.asarray(input_masks, dtype=np.int32), \n",
    "          np.asarray(input_segments, dtype=np.int32)]\n",
    "\n",
    "def create_tonkenizer(bert_layer):\n",
    "    \"\"\"단어집과 소문자로 탑재된 토크나이저로 인스턴스화한다.\"\"\"\n",
    "    vocab_file=bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "    do_lower_case=bert_layer.resolved_object.do_lower_case.numpy() \n",
    "    tokenizer=bert.bert_tokenization.FullTokenizer(vocab_file,do_lower_case)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xs6_p8VTgpoy"
   },
   "source": [
    "## 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C_mFZ2HRcRJB",
    "outputId": "cf1048de-a8e4-43df-e72a-ed744f5c71dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 500)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        [(None, 500)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 500)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "keras_layer (KerasLayer)        [(None, 768), (None, 109482241   input_ids[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 768)          590592      keras_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 768)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            1538        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 110,074,371\n",
      "Trainable params: 110,074,370\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def nlp_model(callable_object):\n",
    "    # 사전훈련된 BERT 모델을 로딩한다.\n",
    "    bert_layer = hub.KerasLayer(handle=callable_object, trainable=True)  \n",
    "   \n",
    "    # BERT 층의 3개 입력: ids, masks와 segments\n",
    "    input_ids = Input(shape=(MAX_SEQ_LEN,), dtype=tf.int32, name=\"input_ids\")           \n",
    "    input_masks = Input(shape=(MAX_SEQ_LEN,), dtype=tf.int32, name=\"input_masks\")       \n",
    "    input_segments = Input(shape=(MAX_SEQ_LEN,), dtype=tf.int32, name=\"segment_ids\")\n",
    "    \n",
    "    inputs = [input_ids, input_masks, input_segments] # BERT inputs\n",
    "    pooled_output, sequence_output = bert_layer(inputs) # BERT outputs\n",
    "    \n",
    "    ###################################\n",
    "    # 문제1: 위의 출력에 Dense (유닛 768) +Dropout (0.1) ,Dense (2)와 softmax를 사용한 후 모델을 완성하라.\n",
    "    # 1. 은익층을 하나 더한다.\n",
    "\n",
    "    \n",
    "    # 2. 출력층을 더한다.\n",
    "\n",
    "    \n",
    "    # 3.새로운 모델을 구축한다.\n",
    "\n",
    "    \n",
    "    ##################################\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = nlp_model(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ViqJURL5qcZJ"
   },
   "source": [
    "## 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XL5LaS68Qo8G",
    "outputId": "7c5747ee-be6f-407c-8466-56ec955f2d76"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40000/40000 [02:04<00:00, 321.27it/s]\n",
      "100%|██████████| 10000/10000 [00:31<00:00, 321.76it/s]\n"
     ]
    }
   ],
   "source": [
    "# 훈련과 테스트를 위한 예제를 만든다.\n",
    "df = df.sample(frac=1) # Shuffle the dataset\n",
    "tokenizer = create_tonkenizer(model.layers[3])\n",
    "X_train = convert_sentences_to_features(df['review'][:40000], tokenizer)\n",
    "X_test = convert_sentences_to_features(df['review'][40000:], tokenizer)\n",
    "\n",
    "df['sentiment'].replace('positive',1.,inplace=True)\n",
    "df['sentiment'].replace('negative',0.,inplace=True)\n",
    "one_hot_encoded = to_categorical(df['sentiment'].values)\n",
    "y_train = one_hot_encoded[:40000]\n",
    "y_test =  one_hot_encoded[40000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IzSF2HJi5XsY",
    "outputId": "1b23b88d-6771-43f4-f81e-287e0cc7b215"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - ETA: 0s - loss: 0.2062 - accuracy: 0.9198WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0111s vs `on_test_batch_end` time: 0.1749s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0111s vs `on_test_batch_end` time: 0.1749s). Check your callbacks.\n"
     ]
    }
   ],
   "source": [
    "# 모델의 훈련l\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 1\n",
    "\n",
    "# 아담 최적화를 사용해 categorical_crossentropy 손실을 최소화한다.\n",
    "opt = Adam(learning_rate=2e-5)\n",
    "model.compile(optimizer=opt, \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 데이터를 모델에 적합화한다.\n",
    "history = model.fit(X_train, y_train,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    epochs=EPOCHS,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    verbose = 1)\n",
    "\n",
    "# 훈련된 모델을 저장한다.\n",
    "model.save('nlp_model.h5') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "toHq_3_Am6if"
   },
   "source": [
    "## 모델 성과 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "fcuvU9EhiFXX"
   },
   "outputs": [],
   "source": [
    "# 사전훈련 자연어처리 모델을 로딩한다.\n",
    "from tensorflow.keras.models import load_model\n",
    "new_model = load_model('nlp_model.h5',custom_objects={'KerasLayer':hub.KerasLayer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "KCqF3D54iGiZ"
   },
   "outputs": [],
   "source": [
    "# 테스트 데이터셋에 대해서 예측한다.\n",
    "from sklearn.metrics import classification_report\n",
    "pred_test = np.argmax(new_model.predict(X_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6pcfuN3wvFJV",
    "outputId": "20a7b7e2-e77e-4426-8dbc-6df141fbb3cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93      5005\n",
      "           1       0.93      0.94      0.93      4995\n",
      "\n",
      "    accuracy                           0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.argmax(y_test,axis=1), pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZxyAqz094Lzv",
    "outputId": "35932357-e957-49a6-b0fc-e90e488bf049"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 0, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "trYqvx4fvrXY",
    "outputId": "9114cf11-29ce-41aa-a57b-4234c5fe14c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7401    Ahh, the dull t.v. shows and pilots that were slammed together in the 70's to make equally dull t.v. movies! Some examples would be Riding With Death(the most hysterically cheesy of the lot), Stranded in Space(confusing and uninteresting), San Francisco International(horribly dull and unbelievably confusing), and this turgid bit of Quinn Martin glamor. <br /><br />Shot in Hawaii(although you wouldn't know it from the outside shots), it's apparently a failed pilot for a lame spy show. The real problem is that you don;'t like most of the characters, including the drab main character Diamond Head, who seemed half asleep for the entire movie; his boss 'Aunt Mary', who had a really weird delivery of his lines and shellacked white hair as well as the a tan that looked like it had been stuccoed on; Diamnd Head's girlfriend/fellow agent(hell, I can't even remember her name) a skinny, wooden woman with a flat way of speaking that is just not sexy or interesting; and the singing sidekick Zul...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트 데이터셋의 첫째 평에 대해 0를 예측했다.\n",
    "df['review'][40000:40001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tut0mHIywx09",
    "outputId": "6096bb59-f8e2-47c0-8e85-bf9d9ec8c0ba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34224    That film is absolutely fantastic!! If you watch it with your friends it can be a very nice day... Obviously you have to know that the film is stupid and very bad directed and acted (Tomba/Unziker what a couple), and that is probably the worse film in the world, but you can enjoy it very much. We watched it in 19 and it was a very nice evening. The best scenes are the first one, when the criminals kill the friend of Alex, and he tries to act like a desperate, and the result is a comic scene of first category... And then when he shows to Leva (Antevleva, what a name) the \"Palassio di giusstissia\", and then the accident of Leva, that once is going on her car out of the road, and a second later, the car is completely empty! What a magic!\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트 데이터셋의 둘째 평에 대해 1을 예측했다.\n",
    "df['review'][40001:40002]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5R89wjoCxaRU",
    "outputId": "6633a62b-900f-49f6-cf3a-e08effeaf834"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4325    Normally I love finding old (and some not-so-old) westerns I haven't seen, to be the entertainment for the evening. It's such a great way to sit back, relax and escape the politics and world problems for a few hours. But this was not to be the case with this version of The Magnificent Seven. The casting and storyline of this series closely follow the Hollywood formula for politically correct entertainment; good old get-your-mind-right, revisionist history, where the 'bad guys' must all be white, male, Confederate (in this case), and preferably Christian (if it can somehow be worked into the script). It's sad, really. The best movies out there, are now and have always been about simply telling a good story up on the big screen - not about forwarding someone's political ideology.\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트 데이터셋의 셋째 평에 대해 1을 예측했다.\n",
    "df['review'][40002:40003]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "NHpBDfDNiCgO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "4-1. TensorFlow2_BERT_Sentiment_Analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
