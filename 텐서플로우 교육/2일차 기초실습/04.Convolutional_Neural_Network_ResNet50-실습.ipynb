{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet50 맛보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "mZTPD0paPVeG",
    "outputId": "f5492060-476c-4f67-ddcb-75f412a9de79"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n",
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "## 라이브러리 불러오기\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "IZ56o0kqU_h3"
   },
   "outputs": [],
   "source": [
    "# ResNet50 for Cifar10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n6RK4QD6SMFx"
   },
   "outputs": [],
   "source": [
    "## Hyperparameters\n",
    "learning_rate = 0.0001\n",
    "training_epochs = 2 #20\n",
    "batch_size = 100\n",
    "img_size = 224\n",
    "n_class = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "79th2CIAhD4Y"
   },
   "outputs": [],
   "source": [
    "## Data 준비\n",
    "\n",
    "## MNIST Dataset #########################################################\n",
    "#mnist = keras.datasets.mnist\n",
    "#class_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "##########################################################################\n",
    "\n",
    "## Fashion MNIST Dataset #################################################\n",
    "#mnist = keras.datasets.fashion_mnist\n",
    "#class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "##########################################################################\n",
    "\n",
    "## Cifar10 Dataset #########################################################\n",
    "cifar = keras.datasets.cifar10\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "77Dur2cMSkK_"
   },
   "outputs": [],
   "source": [
    "## data preprocessing - resize image\n",
    "def img_resize(images, labels):\n",
    "    return tf.image.resize(images, (img_size, img_size)), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "a3q2eXQ1cvsu",
    "outputId": "70190fb3-f62d-46ed-cda9-85975029c81a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "## Dataset 만들기\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar.load_data()    \n",
    "    \n",
    "train_images = train_images.astype(np.float32) / 255.\n",
    "test_images = test_images.astype(np.float32) / 255.\n",
    "#train_images = np.expand_dims(train_images, axis=-1)\n",
    "#test_images = np.expand_dims(test_images, axis=-1)\n",
    "print(train_images.shape)\n",
    "print(test_images.shape)\n",
    "n_train = train_images.shape[0]\n",
    "n_test = test_images.shape[0]\n",
    "    \n",
    "train_labels = to_categorical(train_labels, 10)\n",
    "test_labels = to_categorical(test_labels, 10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "frEBgMy7S9HM"
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(\n",
    "                buffer_size=50000).batch(batch_size).map(img_resize).repeat()\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(\n",
    "                batch_size).map(img_resize).repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ResNet50\n",
    "from keras.layers import Input, Conv2D, Dense, GlobalAveragePooling2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers import Concatenate, Dropout, ZeroPadding2D, BatchNormalization, Add, Flatten\n",
    "from keras import activations\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_identity(x, filters): \n",
    "  #renet block where dimension doesnot change.\n",
    "  #The skip connection is just simple identity conncection\n",
    "  #we will have 3 blocks and then input will be added\n",
    "\n",
    "  x_skip = x # this will be used for addition with the residual block \n",
    "  f1, f2 = filters\n",
    "\n",
    "  #first block \n",
    "  x = Conv2D(f1, kernel_size=(1, 1), strides=(1, 1), padding='valid', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Activation(activations.relu)(x)\n",
    "\n",
    "  #second block # bottleneck (but size kept same with padding)\n",
    "  x = Conv2D(f1, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Activation(activations.relu)(x)\n",
    "\n",
    "  # third block activation used after adding the input\n",
    "  x = Conv2D(f2, kernel_size=(1, 1), strides=(1, 1), padding='valid', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "  x = BatchNormalization()(x)\n",
    "  # x = Activation(activations.relu)(x)\n",
    "\n",
    "  # add the input \n",
    "  x = Add()([x, x_skip])\n",
    "  x = Activation(activations.relu)(x)\n",
    "\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_conv(x, s, filters):\n",
    "  '''\n",
    "  here the input size changes''' \n",
    "  x_skip = x\n",
    "  f1, f2 = filters\n",
    "\n",
    "  # first block\n",
    "  x = Conv2D(f1, kernel_size=(1, 1), strides=(s, s), padding='valid', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "  # when s = 2 then it is like downsizing the feature map\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Activation(activations.relu)(x)\n",
    "\n",
    "  # second block\n",
    "  x = Conv2D(f1, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Activation(activations.relu)(x)\n",
    "\n",
    "  #third block\n",
    "  x = Conv2D(f2, kernel_size=(1, 1), strides=(1, 1), padding='valid', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  # shortcut \n",
    "  x_skip = Conv2D(f2, kernel_size=(1, 1), strides=(s, s), padding='valid', kernel_regularizer=regularizers.l2(0.001))(x_skip)\n",
    "  x_skip = BatchNormalization()(x_skip)\n",
    "\n",
    "  # add \n",
    "  x = Add()([x, x_skip])\n",
    "  x = Activation(activations.relu)(x)\n",
    "\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_im = Input(shape=(train_im.shape[1], train_im.shape[2], train_im.shape[3])) # cifar 10 images size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet50():\n",
    "    \n",
    "  inputs = Input(shape=(img_size, img_size, 3))\n",
    "  x = ZeroPadding2D(padding=(3, 3))(inputs)\n",
    "\n",
    "  # 1st stage\n",
    "  # here we perform maxpooling, see the figure above\n",
    "\n",
    "  x = Conv2D(64, kernel_size=(7, 7), strides=(2, 2))(x)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Activation(activations.relu)(x)\n",
    "  x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "  #2nd stage \n",
    "  # frm here on only conv block and identity block, no pooling\n",
    "\n",
    "  x = res_conv(x, s=1, filters=(64, 256))\n",
    "  x = res_identity(x, filters=(64, 256))\n",
    "  x = res_identity(x, filters=(64, 256))\n",
    "\n",
    "  # 3rd stage\n",
    "\n",
    "  x = res_conv(x, s=2, filters=(128, 512))\n",
    "  x = res_identity(x, filters=(128, 512))\n",
    "  x = res_identity(x, filters=(128, 512))\n",
    "  x = res_identity(x, filters=(128, 512))\n",
    "\n",
    "  # 4th stage\n",
    "\n",
    "  x = res_conv(x, s=2, filters=(256, 1024))\n",
    "  x = res_identity(x, filters=(256, 1024))\n",
    "  x = res_identity(x, filters=(256, 1024))\n",
    "  x = res_identity(x, filters=(256, 1024))\n",
    "  x = res_identity(x, filters=(256, 1024))\n",
    "  x = res_identity(x, filters=(256, 1024))\n",
    "\n",
    "  # 5th stage\n",
    "\n",
    "  x = res_conv(x, s=2, filters=(512, 2048))\n",
    "  x = res_identity(x, filters=(512, 2048))\n",
    "  x = res_identity(x, filters=(512, 2048))\n",
    "\n",
    "  # ends with average pooling and dense connection\n",
    "\n",
    "  x = AveragePooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "  x = Flatten()(x)\n",
    "  x = Dense(10, activation='softmax', kernel_initializer='he_normal')(x) #multi-class\n",
    "\n",
    "  # define the model \n",
    "\n",
    "  return keras.Model(inputs=inputs, outputs=x, name='Resnet50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_17 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_15 (ZeroPadding2 (None, 230, 230, 3)  0           input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 112, 112, 64) 9472        zero_padding2d_15[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, 112, 112, 64) 256         conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 112, 112, 64) 0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 55, 55, 64)   0           activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 55, 55, 64)   4160        max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, 55, 55, 64)   256         conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 55, 55, 64)   0           batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 55, 55, 64)   36928       activation_162[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, 55, 55, 64)   256         conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 55, 55, 64)   0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 55, 55, 256)  16640       activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 55, 55, 256)  16640       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, 55, 55, 256)  1024        conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, 55, 55, 256)  1024        conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_49 (Add)                    (None, 55, 55, 256)  0           batch_normalization_183[0][0]    \n",
      "                                                                 batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 55, 55, 256)  0           add_49[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 55, 55, 64)   16448       activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, 55, 55, 64)   256         conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 55, 55, 64)   0           batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 55, 55, 64)   36928       activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, 55, 55, 64)   256         conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 55, 55, 64)   0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 55, 55, 256)  16640       activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 55, 55, 256)  1024        conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_50 (Add)                    (None, 55, 55, 256)  0           batch_normalization_187[0][0]    \n",
      "                                                                 activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 55, 55, 256)  0           add_50[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 55, 55, 64)   16448       activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 55, 55, 64)   256         conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 55, 55, 64)   0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 55, 55, 64)   36928       activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 55, 55, 64)   256         conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 55, 55, 64)   0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 55, 55, 256)  16640       activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 55, 55, 256)  1024        conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_51 (Add)                    (None, 55, 55, 256)  0           batch_normalization_190[0][0]    \n",
      "                                                                 activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 55, 55, 256)  0           add_51[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 28, 28, 128)  32896       activation_170[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 28, 28, 128)  512         conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 28, 28, 128)  0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 28, 28, 128)  147584      activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 28, 28, 128)  512         conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 28, 28, 128)  0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 28, 28, 512)  66048       activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 28, 28, 512)  131584      activation_170[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 28, 28, 512)  2048        conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 28, 28, 512)  2048        conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_52 (Add)                    (None, 28, 28, 512)  0           batch_normalization_193[0][0]    \n",
      "                                                                 batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 28, 28, 512)  0           add_52[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 28, 28, 128)  65664       activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 28, 28, 128)  512         conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 28, 28, 128)  0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 28, 28, 128)  147584      activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, 28, 28, 128)  512         conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 28, 28, 128)  0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 28, 28, 512)  66048       activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, 28, 28, 512)  2048        conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_53 (Add)                    (None, 28, 28, 512)  0           batch_normalization_197[0][0]    \n",
      "                                                                 activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 28, 28, 512)  0           add_53[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 28, 28, 128)  65664       activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 28, 28, 128)  512         conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 28, 28, 128)  0           batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 28, 28, 128)  147584      activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 28, 28, 128)  512         conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 28, 28, 128)  0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 28, 28, 512)  66048       activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 28, 28, 512)  2048        conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_54 (Add)                    (None, 28, 28, 512)  0           batch_normalization_200[0][0]    \n",
      "                                                                 activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 28, 28, 512)  0           add_54[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 28, 28, 128)  65664       activation_179[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 28, 28, 128)  512         conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 28, 28, 128)  0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 28, 28, 128)  147584      activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 28, 28, 128)  512         conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 28, 28, 128)  0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 28, 28, 512)  66048       activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 28, 28, 512)  2048        conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_55 (Add)                    (None, 28, 28, 512)  0           batch_normalization_203[0][0]    \n",
      "                                                                 activation_179[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 28, 28, 512)  0           add_55[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 14, 14, 256)  131328      activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchN (None, 14, 14, 256)  1024        conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 14, 14, 256)  0           batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 14, 14, 256)  590080      activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, 14, 14, 256)  1024        conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 14, 14, 256)  0           batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, 14, 14, 1024) 263168      activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, 14, 14, 1024) 525312      activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchN (None, 14, 14, 1024) 4096        conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_207 (BatchN (None, 14, 14, 1024) 4096        conv2d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_56 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_206[0][0]    \n",
      "                                                                 batch_normalization_207[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 14, 14, 1024) 0           add_56[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)             (None, 14, 14, 256)  262400      activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_208 (BatchN (None, 14, 14, 256)  1024        conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 14, 14, 256)  0           batch_normalization_208[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)             (None, 14, 14, 256)  590080      activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_209 (BatchN (None, 14, 14, 256)  1024        conv2d_210[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 14, 14, 256)  0           batch_normalization_209[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)             (None, 14, 14, 1024) 263168      activation_187[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_210 (BatchN (None, 14, 14, 1024) 4096        conv2d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_57 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_210[0][0]    \n",
      "                                                                 activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 14, 14, 1024) 0           add_57[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)             (None, 14, 14, 256)  262400      activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_211 (BatchN (None, 14, 14, 256)  1024        conv2d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 14, 14, 256)  0           batch_normalization_211[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)             (None, 14, 14, 256)  590080      activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_212 (BatchN (None, 14, 14, 256)  1024        conv2d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 14, 14, 256)  0           batch_normalization_212[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)             (None, 14, 14, 1024) 263168      activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_213 (BatchN (None, 14, 14, 1024) 4096        conv2d_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_58 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_213[0][0]    \n",
      "                                                                 activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 14, 14, 1024) 0           add_58[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)             (None, 14, 14, 256)  262400      activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_214 (BatchN (None, 14, 14, 256)  1024        conv2d_215[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 14, 14, 256)  0           batch_normalization_214[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_216 (Conv2D)             (None, 14, 14, 256)  590080      activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_215 (BatchN (None, 14, 14, 256)  1024        conv2d_216[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 14, 14, 256)  0           batch_normalization_215[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_217 (Conv2D)             (None, 14, 14, 1024) 263168      activation_193[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_216 (BatchN (None, 14, 14, 1024) 4096        conv2d_217[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_59 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_216[0][0]    \n",
      "                                                                 activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 14, 14, 1024) 0           add_59[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_218 (Conv2D)             (None, 14, 14, 256)  262400      activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_217 (BatchN (None, 14, 14, 256)  1024        conv2d_218[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 14, 14, 256)  0           batch_normalization_217[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_219 (Conv2D)             (None, 14, 14, 256)  590080      activation_195[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_218 (BatchN (None, 14, 14, 256)  1024        conv2d_219[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, 14, 14, 256)  0           batch_normalization_218[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_220 (Conv2D)             (None, 14, 14, 1024) 263168      activation_196[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_219 (BatchN (None, 14, 14, 1024) 4096        conv2d_220[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_60 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_219[0][0]    \n",
      "                                                                 activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 14, 14, 1024) 0           add_60[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_221 (Conv2D)             (None, 14, 14, 256)  262400      activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_220 (BatchN (None, 14, 14, 256)  1024        conv2d_221[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, 14, 14, 256)  0           batch_normalization_220[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_222 (Conv2D)             (None, 14, 14, 256)  590080      activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_221 (BatchN (None, 14, 14, 256)  1024        conv2d_222[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 14, 14, 256)  0           batch_normalization_221[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_223 (Conv2D)             (None, 14, 14, 1024) 263168      activation_199[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_222 (BatchN (None, 14, 14, 1024) 4096        conv2d_223[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_61 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_222[0][0]    \n",
      "                                                                 activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 14, 14, 1024) 0           add_61[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_224 (Conv2D)             (None, 7, 7, 512)    524800      activation_200[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_223 (BatchN (None, 7, 7, 512)    2048        conv2d_224[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, 7, 7, 512)    0           batch_normalization_223[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_225 (Conv2D)             (None, 7, 7, 512)    2359808     activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_224 (BatchN (None, 7, 7, 512)    2048        conv2d_225[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, 7, 7, 512)    0           batch_normalization_224[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_226 (Conv2D)             (None, 7, 7, 2048)   1050624     activation_202[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_227 (Conv2D)             (None, 7, 7, 2048)   2099200     activation_200[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_225 (BatchN (None, 7, 7, 2048)   8192        conv2d_226[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_226 (BatchN (None, 7, 7, 2048)   8192        conv2d_227[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_62 (Add)                    (None, 7, 7, 2048)   0           batch_normalization_225[0][0]    \n",
      "                                                                 batch_normalization_226[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, 7, 7, 2048)   0           add_62[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_228 (Conv2D)             (None, 7, 7, 512)    1049088     activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_227 (BatchN (None, 7, 7, 512)    2048        conv2d_228[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_204 (Activation)     (None, 7, 7, 512)    0           batch_normalization_227[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_229 (Conv2D)             (None, 7, 7, 512)    2359808     activation_204[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_228 (BatchN (None, 7, 7, 512)    2048        conv2d_229[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_205 (Activation)     (None, 7, 7, 512)    0           batch_normalization_228[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_230 (Conv2D)             (None, 7, 7, 2048)   1050624     activation_205[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_229 (BatchN (None, 7, 7, 2048)   8192        conv2d_230[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_63 (Add)                    (None, 7, 7, 2048)   0           batch_normalization_229[0][0]    \n",
      "                                                                 activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_206 (Activation)     (None, 7, 7, 2048)   0           add_63[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_231 (Conv2D)             (None, 7, 7, 512)    1049088     activation_206[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_230 (BatchN (None, 7, 7, 512)    2048        conv2d_231[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_207 (Activation)     (None, 7, 7, 512)    0           batch_normalization_230[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_232 (Conv2D)             (None, 7, 7, 512)    2359808     activation_207[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_231 (BatchN (None, 7, 7, 512)    2048        conv2d_232[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_208 (Activation)     (None, 7, 7, 512)    0           batch_normalization_231[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_233 (Conv2D)             (None, 7, 7, 2048)   1050624     activation_208[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_232 (BatchN (None, 7, 7, 2048)   8192        conv2d_233[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_64 (Add)                    (None, 7, 7, 2048)   0           batch_normalization_232[0][0]    \n",
      "                                                                 activation_206[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_209 (Activation)     (None, 7, 7, 2048)   0           add_64[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 4, 4, 2048)   0           activation_209[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 32768)        0           average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           327690      flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 23,915,402\n",
      "Trainable params: 23,862,282\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=resnet50()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "12BNMqSaY75u"
   },
   "outputs": [],
   "source": [
    "## Model Compile\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "NDijIPrZdBn0",
    "outputId": "888fd22f-d19e-4c5f-e8d4-8f9ec04dc60f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 1407s 14s/step - loss: 20.3693 - accuracy: 0.1065\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[20.369338989257812, 0.10649999976158142]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_per_epoch = n_train/batch_size\n",
    "validation_steps = n_test/batch_size\n",
    "\n",
    "model.evaluate(test_dataset, steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 796
    },
    "colab_type": "code",
    "id": "9iss9p2jZDHr",
    "outputId": "7e4bcea2-38d1-4837-b355-08b8c3150329"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      " 99/500 [====>.........................] - ETA: 12:02:11 - loss: 20.7963 - accuracy: 0.2004"
     ]
    }
   ],
   "source": [
    "## Training\n",
    "history = model.fit(train_dataset, epochs=training_epochs, steps_per_epoch=steps_per_epoch,\n",
    "                    validation_data=test_dataset, validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yes8udvYhUBI"
   },
   "outputs": [],
   "source": [
    "def plot_image(i, predictions_array, true_label, img):\n",
    "    predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.imshow(img)\n",
    "\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    if predicted_label == true_label:\n",
    "        color = 'blue'\n",
    "    else:\n",
    "        color = 'red'\n",
    "\n",
    "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                100*np.max(predictions_array),\n",
    "                                class_names[true_label]),\n",
    "                                color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "    predictions_array, true_label = predictions_array[i], true_label[i]\n",
    "    plt.grid(False)\n",
    "    #plt.xticks([])\n",
    "    plt.xticks(range(n_class), class_names, rotation=90)\n",
    "    plt.yticks([])\n",
    "    thisplot = plt.bar(range(n_class), predictions_array, color=\"#777777\")\n",
    "    plt.ylim([0, 1]) \n",
    "    predicted_label = np.argmax(predictions_array)\n",
    " \n",
    "    thisplot[predicted_label].set_color('red')\n",
    "    thisplot[true_label].set_color('blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "FXIMMPMqZLwX",
    "outputId": "36e14e5b-823b-4f20-d9ae-4a334bebdf3b"
   },
   "outputs": [],
   "source": [
    "rnd_idx = np.random.randint(1, n_test//batch_size)\n",
    "img_cnt = 0\n",
    "for images, labels in test_dataset:\n",
    "    img_cnt += 1\n",
    "    if img_cnt != rnd_idx:\n",
    "        continue\n",
    "    predictions = model(images, training=False)\n",
    "    num_rows = 5\n",
    "    num_cols = 3\n",
    "    num_images = num_rows*num_cols\n",
    "    labels = tf.argmax(labels, axis=-1)\n",
    "    plt.figure(figsize=(3*2*num_cols, 4*num_rows))\n",
    "    plt.subplots_adjust(hspace=1.0)\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "        plot_image(i, predictions.numpy(), labels.numpy(), images.numpy())\n",
    "        plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "        plot_value_array(i, predictions.numpy(), labels.numpy())        \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qxiHCXJdjX00"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "7.Convolutional_Neural_Network_GoogLeNet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
